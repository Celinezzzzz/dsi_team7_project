{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge\n",
      "  Index        Date         Open         High          Low        Close  \\\n",
      "0   HSI  1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049   \n",
      "1   HSI  1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098   \n",
      "2   HSI  1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902   \n",
      "3   HSI  1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902   \n",
      "4   HSI  1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098   \n",
      "\n",
      "     Adj Close  Volume    CloseUSD     Region                  Exchange  \n",
      "0  2568.300049     0.0  333.879006  Hong Kong  Hong Kong Stock Exchange  \n",
      "1  2540.100098     0.0  330.213013  Hong Kong  Hong Kong Stock Exchange  \n",
      "2  2552.399902     0.0  331.811987  Hong Kong  Hong Kong Stock Exchange  \n",
      "3  2583.899902     0.0  335.906987  Hong Kong  Hong Kong Stock Exchange  \n",
      "4  2607.100098     0.0  338.923013  Hong Kong  Hong Kong Stock Exchange  \n",
      "Index(['Index', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n",
      "       'CloseUSD', 'Region', 'Exchange', 'price_diff', 'ma_5', 'ma_10',\n",
      "       'ma_30', 'volatility', 'pct_return', 'price_direction'],\n",
      "      dtype='object')\n",
      "Index(['index_stock', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close',\n",
      "       'Volume', 'CloseUSD', 'Region', 'Exchange', 'price_diff', 'ma_5',\n",
      "       'ma_10', 'ma_30', 'volatility', 'pct_return', 'price_direction'],\n",
      "      dtype='object')\n",
      "Number of rows: 100673\n",
      "Index(['index_stock', 'open', 'high', 'low', 'close', 'adj close', 'volume',\n",
      "       'closeusd', 'region', 'exchange', 'price_diff', 'ma_5', 'ma_10',\n",
      "       'ma_30', 'volatility', 'pct_return', 'price_direction', 'macd',\n",
      "       'rsi_12', 'close_5_sma', 'close_10_ema'],\n",
      "      dtype='object')\n",
      "Number of rows: 61088\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as psql\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/raw/indexProcessed.csv' \n",
    "file_path2 = '../data/raw/indexInfo.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "# Drop the 'currency' column from df2\n",
    "df2 = df2.drop(columns=['Currency'])\n",
    "df = pd.merge(df, df2, on='Index', how='left')\n",
    "print(\"merge\")\n",
    "print (df.head())\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM df\n",
    "WHERE Open IS NOT NULL\n",
    "AND Close IS NOT NULL\n",
    "AND Volume IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "df_cleaned = psql.sqldf(query, locals())\n",
    "\n",
    "\n",
    "# 1. Drop rows with any missing (NaN) values\n",
    "#df_cleaned = df.dropna()\n",
    "\n",
    "# Define thresholds for outliers based on the 1st and 99th percentiles for each feature\n",
    "\n",
    "volume_threshold = (df_cleaned['Volume'].quantile(0.01), df_cleaned['Volume'].quantile(0.99))\n",
    "open_threshold = (df_cleaned['Open'].quantile(0.01), df_cleaned['Open'].quantile(0.99))\n",
    "high_threshold = (df_cleaned['High'].quantile(0.01), df_cleaned['High'].quantile(0.99))\n",
    "low_threshold = (df_cleaned['Low'].quantile(0.01), df_cleaned['Low'].quantile(0.99))\n",
    "close_threshold = (df_cleaned['Close'].quantile(0.01), df_cleaned['Close'].quantile(0.99))\n",
    "adj_close_threshold = (df_cleaned['Adj Close'].quantile(0.01), df_cleaned['Adj Close'].quantile(0.99))\n",
    "\n",
    "# Remove rows where 'Volume', 'Open', 'High', 'Low', 'Close', or 'Adj Close' fall outside of these thresholds\n",
    "df_cleaned = df_cleaned[\n",
    "    (df_cleaned['Volume'] >= volume_threshold[0]) & (df_cleaned['Volume'] <= volume_threshold[1]) &\n",
    "    (df_cleaned['Open'] >= open_threshold[0]) & (df_cleaned['Open'] <= open_threshold[1]) &\n",
    "    (df_cleaned['High'] >= high_threshold[0]) & (df_cleaned['High'] <= high_threshold[1]) &\n",
    "    (df_cleaned['Low'] >= low_threshold[0]) & (df_cleaned['Low'] <= low_threshold[1]) &\n",
    "    (df_cleaned['Close'] >= close_threshold[0]) & (df_cleaned['Close'] <= close_threshold[1]) &\n",
    "    (df_cleaned['Adj Close'] >= adj_close_threshold[0]) & (df_cleaned['Adj Close'] <= adj_close_threshold[1])\n",
    "]\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
    "\n",
    "# 3. Remove Duplicates (if any)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# 4. (Optional) Filter rows based on a specific date range (assuming there's a 'Date' column)\n",
    "# Convert 'Date' column to datetime if needed\n",
    "\n",
    "# 5. Example of creating a new feature (similar to `CloseUSD`)\n",
    "# Let's assume we are converting 'Close' price to USD using a fixed exchange rate\n",
    "#usd_conversion_rate = 0.85  # Example conversion rate\n",
    "#df_cleaned['CloseUSD'] = df_cleaned['Close'] * usd_conversion_rate\n",
    "\n",
    "# Create daily price difference\n",
    "df_cleaned['price_diff'] = df_cleaned['Close'] - df_cleaned['Open']\n",
    "\n",
    "# Calculate moving averages for closing prices (5-day, 10-day, 30-day)\n",
    "# df_cleaned['ma_5'] = df_cleaned['Close'].rolling(window=5).mean()\n",
    "# df_cleaned['ma_10'] = df_cleaned['Close'].rolling(window=10).mean()\n",
    "# df_cleaned['ma_30'] = df_cleaned['Close'].rolling(window=30).mean()\n",
    "\n",
    "df_cleaned['ma_5'] = df_cleaned.groupby('Index')['Close'].rolling(window=5).mean().reset_index(level=0, drop=True)\n",
    "df_cleaned['ma_10'] = df_cleaned.groupby('Index')['Close'].rolling(window=10).mean().reset_index(level=0, drop=True)\n",
    "df_cleaned['ma_30'] = df_cleaned.groupby('Index')['Close'].rolling(window=30).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate daily volatility using high and low prices\n",
    "df_cleaned['volatility'] = df_cleaned['High'] - df_cleaned['Low']\n",
    "\n",
    "# Calculate percentage returns\n",
    "df_cleaned['pct_return'] = df_cleaned['Close'].pct_change()\n",
    "\n",
    "# Drop the first row due to NaN values created by pct_change\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a target variable: 1 if next day's closing price increases, 0 otherwise\n",
    "df_cleaned['price_direction'] = (df_cleaned['Close'].shift(-1) > df_cleaned['Close']).astype(int)\n",
    "\n",
    "\n",
    "#df_cleaned['Up_Or_Down'] = np.where (df_cleaned['Close'].shift(-1) > df_cleaned['Close'],1,0)\n",
    "\n",
    "\n",
    "# Drop the last row since it won't have a target value\n",
    "#data = data[:-1]\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "# Display the new features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_cleaned = df_cleaned.rename(columns={'Index': 'index_stock'})\n",
    "print(df_cleaned.columns)\n",
    "date_col = df_cleaned['Date'].copy()\n",
    "num_rows = len(df_cleaned)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "\n",
    "df_cleaned.to_csv('../data/processed/indexData_processed_before_calculation.csv', index=False)\n",
    "\n",
    "\n",
    "stock = Sdf.retype(df_cleaned)\n",
    "\n",
    "\n",
    "#Moving Average Convergence Divergence\n",
    "df_cleaned['macd']=stock['macd']\n",
    "df_cleaned['rsi_12']=stock['rsi_12']\n",
    "#df_cleaned['cci_10']=stock['cci_10']\n",
    "#df_cleaned['wr_6'] = stock['wr_6']\n",
    "df_cleaned['close_5_sma']=stock['close_5_sma']\n",
    "df_cleaned['close_10_ema'] = stock['close_10_ema']\n",
    "\n",
    "\n",
    "# Remove rows with zeros in specified columns\n",
    "df_cleaned = df_cleaned[(df_cleaned[['macd', 'rsi_12', 'close_5_sma', 'close_10_ema', 'volume']] != 0).all(axis=1)]\n",
    "\n",
    "\n",
    "# Show the result\n",
    "print(df_cleaned.columns)\n",
    "num_rows = len(df_cleaned)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "# Save the cleaned dataset if needed\n",
    "df_cleaned.to_csv('../data/processed/indexData_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
