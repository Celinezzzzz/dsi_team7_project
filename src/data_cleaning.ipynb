{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as psql\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/raw/indexData.csv'\n",
    "file_path2 = '../data/raw/indexInfo.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df2 = pd.read_csv(file_path2)\n",
    "df = pd.merge(df, df2, on='Index', how='left')\n",
    "print(\"merge\")\n",
    "print (df.head())\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM df\n",
    "WHERE Open IS NOT NULL\n",
    "AND Close IS NOT NULL\n",
    "AND Volume IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "df_cleaned = psql.sqldf(query, locals())\n",
    "\n",
    "\n",
    "# 1. Drop rows with any missing (NaN) values\n",
    "#df_cleaned = df.dropna()\n",
    "\n",
    "# Define thresholds for outliers based on the 1st and 99th percentiles for each feature\n",
    "\n",
    "volume_threshold = (df_cleaned['Volume'].quantile(0.01), df_cleaned['Volume'].quantile(0.99))\n",
    "open_threshold = (df_cleaned['Open'].quantile(0.01), df_cleaned['Open'].quantile(0.99))\n",
    "high_threshold = (df_cleaned['High'].quantile(0.01), df_cleaned['High'].quantile(0.99))\n",
    "low_threshold = (df_cleaned['Low'].quantile(0.01), df_cleaned['Low'].quantile(0.99))\n",
    "close_threshold = (df_cleaned['Close'].quantile(0.01), df_cleaned['Close'].quantile(0.99))\n",
    "adj_close_threshold = (df_cleaned['Adj Close'].quantile(0.01), df_cleaned['Adj Close'].quantile(0.99))\n",
    "\n",
    "# Remove rows where 'Volume', 'Open', 'High', 'Low', 'Close', or 'Adj Close' fall outside of these thresholds\n",
    "df_cleaned = df_cleaned[\n",
    "    (df_cleaned['Volume'] >= volume_threshold[0]) & (df_cleaned['Volume'] <= volume_threshold[1]) &\n",
    "    (df_cleaned['Open'] >= open_threshold[0]) & (df_cleaned['Open'] <= open_threshold[1]) &\n",
    "    (df_cleaned['High'] >= high_threshold[0]) & (df_cleaned['High'] <= high_threshold[1]) &\n",
    "    (df_cleaned['Low'] >= low_threshold[0]) & (df_cleaned['Low'] <= low_threshold[1]) &\n",
    "    (df_cleaned['Close'] >= close_threshold[0]) & (df_cleaned['Close'] <= close_threshold[1]) &\n",
    "    (df_cleaned['Adj Close'] >= adj_close_threshold[0]) & (df_cleaned['Adj Close'] <= adj_close_threshold[1])\n",
    "]\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
    "\n",
    "# 3. Remove Duplicates (if any)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# 4. (Optional) Filter rows based on a specific date range (assuming there's a 'Date' column)\n",
    "# Convert 'Date' column to datetime if needed\n",
    "\n",
    "# 5. Example of creating a new feature (similar to `CloseUSD`)\n",
    "# Let's assume we are converting 'Close' price to USD using a fixed exchange rate\n",
    "#usd_conversion_rate = 0.85  # Example conversion rate\n",
    "#df_cleaned['CloseUSD'] = df_cleaned['Close'] * usd_conversion_rate\n",
    "\n",
    "# Create daily price difference\n",
    "df_cleaned['price_diff'] = df_cleaned['Close'] - df_cleaned['Open']\n",
    "\n",
    "# Calculate moving averages for closing prices (5-day, 10-day, 30-day)\n",
    "# df_cleaned['ma_5'] = df_cleaned['Close'].rolling(window=5).mean()\n",
    "# df_cleaned['ma_10'] = df_cleaned['Close'].rolling(window=10).mean()\n",
    "# df_cleaned['ma_30'] = df_cleaned['Close'].rolling(window=30).mean()\n",
    "\n",
    "df_cleaned['ma_5'] = df_cleaned.groupby('Index')['Close'].rolling(window=5).mean().reset_index(level=0, drop=True)\n",
    "df_cleaned['ma_10'] = df_cleaned.groupby('Index')['Close'].rolling(window=10).mean().reset_index(level=0, drop=True)\n",
    "df_cleaned['ma_30'] = df_cleaned.groupby('Index')['Close'].rolling(window=30).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate daily volatility using high and low prices\n",
    "df_cleaned['volatility'] = df_cleaned['High'] - df_cleaned['Low']\n",
    "\n",
    "# Calculate percentage returns\n",
    "df_cleaned['pct_return'] = df_cleaned['Close'].pct_change()\n",
    "\n",
    "# Drop the first row due to NaN values created by pct_change\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a target variable: 1 if next day's closing price increases, 0 otherwise\n",
    "df_cleaned['price_direction'] = (df_cleaned['Close'].shift(-1) > df_cleaned['Close']).astype(int)\n",
    "\n",
    "\n",
    "df_cleaned['Up_Or_Down'] = np.where (df_cleaned['Close'].shift(-1) > df_cleaned['Close'],1,0)\n",
    "\n",
    "\n",
    "# Drop the last row since it won't have a target value\n",
    "#data = data[:-1]\n",
    "print(df_cleaned.columns)\n",
    "\n",
    "# Display the new features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_cleaned = df_cleaned.rename(columns={'Index': 'index_stock'})\n",
    "print(df_cleaned.columns)\n",
    "date_col = df_cleaned['Date'].copy()\n",
    "num_rows = len(df_cleaned)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "\n",
    "\n",
    "\n",
    "df_cleaned.to_csv('../data/processed/indexData_processed_before_calculation.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "stock = Sdf.retype(df_cleaned)\n",
    "\n",
    "\n",
    "print(df_cleaned.columns)\n",
    "#Moving Average Convergence Divergence\n",
    "df_cleaned['macd']=stock['macd']\n",
    "df_cleaned['boll']=stock['boll']\n",
    "df_cleaned['rsi_12']=stock['rsi_12']\n",
    "df_cleaned['close_5_sma']=stock['close_5_sma']\n",
    "df_cleaned['close_10_ema'] = stock['close_10_ema']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show the result\n",
    "print(df_cleaned.columns)\n",
    "num_rows = len(df_cleaned)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "# Save the cleaned dataset if needed\n",
    "df_cleaned.to_csv('../data/processed/indexData_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
