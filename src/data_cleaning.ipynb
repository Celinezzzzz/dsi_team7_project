{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    price_diff        ma_5       ma_10       ma_30  volatility  pct_return  \\\n",
      "29         0.0  537.566003  534.946002  534.558667         0.0   -0.002741   \n",
      "30         0.0  538.138001  535.210004  534.879333         0.0   -0.000186   \n",
      "31         0.0  538.244006  535.654004  535.231667         0.0   -0.000985   \n",
      "32         0.0  537.968005  536.288007  535.485333         0.0   -0.004333   \n",
      "33         0.0  537.059998  536.679004  535.626333         0.0   -0.000187   \n",
      "\n",
      "    price_direction  \n",
      "29                0  \n",
      "30                0  \n",
      "31                0  \n",
      "32                0  \n",
      "33                0  \n",
      "   Index       Date        Open        High         Low       Close  \\\n",
      "29   NYA 1966-02-10  538.409973  538.409973  538.409973  538.409973   \n",
      "30   NYA 1966-02-11  538.309998  538.309998  538.309998  538.309998   \n",
      "31   NYA 1966-02-14  537.780029  537.780029  537.780029  537.780029   \n",
      "32   NYA 1966-02-15  535.450012  535.450012  535.450012  535.450012   \n",
      "33   NYA 1966-02-16  535.349976  535.349976  535.349976  535.349976   \n",
      "\n",
      "     Adj Close  Volume  price_diff        ma_5       ma_10       ma_30  \\\n",
      "29  538.409973     0.0         0.0  537.566003  534.946002  534.558667   \n",
      "30  538.309998     0.0         0.0  538.138001  535.210004  534.879333   \n",
      "31  537.780029     0.0         0.0  538.244006  535.654004  535.231667   \n",
      "32  535.450012     0.0         0.0  537.968005  536.288007  535.485333   \n",
      "33  535.349976     0.0         0.0  537.059998  536.679004  535.626333   \n",
      "\n",
      "    volatility  pct_return  price_direction  \n",
      "29         0.0   -0.002741                0  \n",
      "30         0.0   -0.000186                0  \n",
      "31         0.0   -0.000985                0  \n",
      "32         0.0   -0.004333                0  \n",
      "33         0.0   -0.000187                0  \n",
      "Number of rows: 106870\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as psql\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/raw/indexData.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM df\n",
    "WHERE Open IS NOT NULL\n",
    "AND Close IS NOT NULL\n",
    "AND Volume IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "df_cleaned = psql.sqldf(query, locals())\n",
    "\n",
    "\n",
    "# 1. Drop rows with any missing (NaN) values\n",
    "#df_cleaned = df.dropna()\n",
    "\n",
    "# Define thresholds for outliers based on the 1st and 99th percentiles for each feature\n",
    "\n",
    "volume_threshold = (df_cleaned['Volume'].quantile(0.01), df_cleaned['Volume'].quantile(0.99))\n",
    "open_threshold = (df_cleaned['Open'].quantile(0.01), df_cleaned['Open'].quantile(0.99))\n",
    "high_threshold = (df_cleaned['High'].quantile(0.01), df_cleaned['High'].quantile(0.99))\n",
    "low_threshold = (df_cleaned['Low'].quantile(0.01), df_cleaned['Low'].quantile(0.99))\n",
    "close_threshold = (df_cleaned['Close'].quantile(0.01), df_cleaned['Close'].quantile(0.99))\n",
    "adj_close_threshold = (df_cleaned['Adj Close'].quantile(0.01), df_cleaned['Adj Close'].quantile(0.99))\n",
    "\n",
    "# Remove rows where 'Volume', 'Open', 'High', 'Low', 'Close', or 'Adj Close' fall outside of these thresholds\n",
    "df_cleaned = df_cleaned[\n",
    "    (df_cleaned['Volume'] >= volume_threshold[0]) & (df_cleaned['Volume'] <= volume_threshold[1]) &\n",
    "    (df_cleaned['Open'] >= open_threshold[0]) & (df_cleaned['Open'] <= open_threshold[1]) &\n",
    "    (df_cleaned['High'] >= high_threshold[0]) & (df_cleaned['High'] <= high_threshold[1]) &\n",
    "    (df_cleaned['Low'] >= low_threshold[0]) & (df_cleaned['Low'] <= low_threshold[1]) &\n",
    "    (df_cleaned['Close'] >= close_threshold[0]) & (df_cleaned['Close'] <= close_threshold[1]) &\n",
    "    (df_cleaned['Adj Close'] >= adj_close_threshold[0]) & (df_cleaned['Adj Close'] <= adj_close_threshold[1])\n",
    "]\n",
    "\n",
    "# 3. Remove Duplicates (if any)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# 4. (Optional) Filter rows based on a specific date range (assuming there's a 'Date' column)\n",
    "# Convert 'Date' column to datetime if needed\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
    "\n",
    "# 5. Example of creating a new feature (similar to `CloseUSD`)\n",
    "# Let's assume we are converting 'Close' price to USD using a fixed exchange rate\n",
    "#usd_conversion_rate = 0.85  # Example conversion rate\n",
    "#df_cleaned['CloseUSD'] = df_cleaned['Close'] * usd_conversion_rate\n",
    "\n",
    "\n",
    "\n",
    "# Create daily price difference\n",
    "df_cleaned['price_diff'] = df_cleaned['Close'] - df_cleaned['Open']\n",
    "\n",
    "# Calculate moving averages for closing prices (5-day, 10-day, 30-day)\n",
    "df_cleaned['ma_5'] = df_cleaned['Close'].rolling(window=5).mean()\n",
    "df_cleaned['ma_10'] = df_cleaned['Close'].rolling(window=10).mean()\n",
    "df_cleaned['ma_30'] = df_cleaned['Close'].rolling(window=30).mean()\n",
    "\n",
    "# Calculate daily volatility using high and low prices\n",
    "df_cleaned['volatility'] = df_cleaned['High'] - df_cleaned['Low']\n",
    "\n",
    "# Calculate percentage returns\n",
    "df_cleaned['pct_return'] = df_cleaned['Close'].pct_change()\n",
    "\n",
    "# Drop the first row due to NaN values created by pct_change\n",
    "df_cleaned = df_cleaned.dropna()\n",
    "\n",
    "# Create a target variable: 1 if next day's closing price increases, 0 otherwise\n",
    "df_cleaned['price_direction'] = (df_cleaned['Close'].shift(-1) > df_cleaned['Close']).astype(int)\n",
    "\n",
    "# Drop the last row since it won't have a target value\n",
    "#data = data[:-1]\n",
    "\n",
    "# Display the new features\n",
    "print(df_cleaned[['price_diff', 'ma_5', 'ma_10', 'ma_30', 'volatility', 'pct_return', 'price_direction']].head())\n",
    "\n",
    "# Show the result\n",
    "print(df_cleaned.head())\n",
    "num_rows = len(df_cleaned)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "# Save the cleaned dataset if needed\n",
    "df_cleaned.to_csv('../data/processed/indexData_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
