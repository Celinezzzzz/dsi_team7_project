{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Besher\\AppData\\Local\\Temp\\ipykernel_6616\\1688797603.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['price_direction'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    price_diff        ma_5       ma_10       ma_30  volatility  pct_return  \\\n",
      "29         0.0  537.566003  534.946002  534.558667         0.0   -0.002741   \n",
      "30         0.0  538.138001  535.210004  534.879333         0.0   -0.000186   \n",
      "31         0.0  538.244006  535.654004  535.231667         0.0   -0.000985   \n",
      "32         0.0  537.968005  536.288007  535.485333         0.0   -0.004333   \n",
      "33         0.0  537.059998  536.679004  535.626333         0.0   -0.000187   \n",
      "\n",
      "    price_direction  \n",
      "29                0  \n",
      "30                0  \n",
      "31                0  \n",
      "32                0  \n",
      "33                0  \n",
      "  Index       Date        Open        High         Low       Close  \\\n",
      "0   NYA 1965-12-31  528.690002  528.690002  528.690002  528.690002   \n",
      "1   NYA 1966-01-03  527.210022  527.210022  527.210022  527.210022   \n",
      "2   NYA 1966-01-04  527.840027  527.840027  527.840027  527.840027   \n",
      "3   NYA 1966-01-05  531.119995  531.119995  531.119995  531.119995   \n",
      "4   NYA 1966-01-06  532.070007  532.070007  532.070007  532.070007   \n",
      "\n",
      "    Adj Close  Volume    CloseUSD  price_diff        ma_5  ma_10  ma_30  \\\n",
      "0  528.690002     0.0  449.386502         0.0         NaN    NaN    NaN   \n",
      "1  527.210022     0.0  448.128519         0.0         NaN    NaN    NaN   \n",
      "2  527.840027     0.0  448.664023         0.0         NaN    NaN    NaN   \n",
      "3  531.119995     0.0  451.451996         0.0         NaN    NaN    NaN   \n",
      "4  532.070007     0.0  452.259506         0.0  529.386011    NaN    NaN   \n",
      "\n",
      "   volatility  pct_return  \n",
      "0         0.0         NaN  \n",
      "1         0.0   -0.002799  \n",
      "2         0.0    0.001195  \n",
      "3         0.0    0.006214  \n",
      "4         0.0    0.001789  \n",
      "Number of rows: 106899\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as psql\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/raw/indexData.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT * \n",
    "FROM df\n",
    "WHERE Open IS NOT NULL\n",
    "AND Close IS NOT NULL\n",
    "AND Volume IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "df_cleaned = psql.sqldf(query, locals())\n",
    "\n",
    "\n",
    "# 1. Drop rows with any missing (NaN) values\n",
    "#df_cleaned = df.dropna()\n",
    "\n",
    "# Define thresholds for outliers based on the 1st and 99th percentiles for each feature\n",
    "\n",
    "volume_threshold = (df_cleaned['Volume'].quantile(0.01), df_cleaned['Volume'].quantile(0.99))\n",
    "open_threshold = (df_cleaned['Open'].quantile(0.01), df_cleaned['Open'].quantile(0.99))\n",
    "high_threshold = (df_cleaned['High'].quantile(0.01), df_cleaned['High'].quantile(0.99))\n",
    "low_threshold = (df_cleaned['Low'].quantile(0.01), df_cleaned['Low'].quantile(0.99))\n",
    "close_threshold = (df_cleaned['Close'].quantile(0.01), df_cleaned['Close'].quantile(0.99))\n",
    "adj_close_threshold = (df_cleaned['Adj Close'].quantile(0.01), df_cleaned['Adj Close'].quantile(0.99))\n",
    "\n",
    "# Remove rows where 'Volume', 'Open', 'High', 'Low', 'Close', or 'Adj Close' fall outside of these thresholds\n",
    "df_cleaned = df_cleaned[\n",
    "    (df_cleaned['Volume'] >= volume_threshold[0]) & (df_cleaned['Volume'] <= volume_threshold[1]) &\n",
    "    (df_cleaned['Open'] >= open_threshold[0]) & (df_cleaned['Open'] <= open_threshold[1]) &\n",
    "    (df_cleaned['High'] >= high_threshold[0]) & (df_cleaned['High'] <= high_threshold[1]) &\n",
    "    (df_cleaned['Low'] >= low_threshold[0]) & (df_cleaned['Low'] <= low_threshold[1]) &\n",
    "    (df_cleaned['Close'] >= close_threshold[0]) & (df_cleaned['Close'] <= close_threshold[1]) &\n",
    "    (df_cleaned['Adj Close'] >= adj_close_threshold[0]) & (df_cleaned['Adj Close'] <= adj_close_threshold[1])\n",
    "]\n",
    "\n",
    "# 3. Remove Duplicates (if any)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# 4. (Optional) Filter rows based on a specific date range (assuming there's a 'Date' column)\n",
    "# Convert 'Date' column to datetime if needed\n",
    "df_cleaned['Date'] = pd.to_datetime(df_cleaned['Date'])\n",
    "\n",
    "# 5. Example of creating a new feature (similar to `CloseUSD`)\n",
    "# Let's assume we are converting 'Close' price to USD using a fixed exchange rate\n",
    "usd_conversion_rate = 0.85  # Example conversion rate\n",
    "df_cleaned['CloseUSD'] = df_cleaned['Close'] * usd_conversion_rate\n",
    "\n",
    "\n",
    "\n",
    "# Create daily price difference\n",
    "df_cleaned['price_diff'] = df_cleaned['Close'] - df_cleaned['Open']\n",
    "\n",
    "# Calculate moving averages for closing prices (5-day, 10-day, 30-day)\n",
    "df_cleaned['ma_5'] = df_cleaned['Close'].rolling(window=5).mean()\n",
    "df_cleaned['ma_10'] = df_cleaned['Close'].rolling(window=10).mean()\n",
    "df_cleaned['ma_30'] = df_cleaned['Close'].rolling(window=30).mean()\n",
    "\n",
    "# Calculate daily volatility using high and low prices\n",
    "df_cleaned['volatility'] = df_cleaned['High'] - df_cleaned['Low']\n",
    "\n",
    "# Calculate percentage returns\n",
    "df_cleaned['pct_return'] = df_cleaned['Close'].pct_change()\n",
    "\n",
    "# Drop the first row due to NaN values created by pct_change\n",
    "data = df_cleaned.dropna()\n",
    "\n",
    "# Create a target variable: 1 if next day's closing price increases, 0 otherwise\n",
    "data['price_direction'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
    "\n",
    "# Drop the last row since it won't have a target value\n",
    "#data = data[:-1]\n",
    "\n",
    "# Display the new features\n",
    "print(data[['price_diff', 'ma_5', 'ma_10', 'ma_30', 'volatility', 'pct_return', 'price_direction']].head())\n",
    "\n",
    "# Show the result\n",
    "print(df_cleaned.head())\n",
    "num_rows = len(df_cleaned)\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "# Save the cleaned dataset if needed\n",
    "df_cleaned.to_csv('../data/processed/indexData_processed.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
